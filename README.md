# MPIVector
MPI2が制定されてから10年以上進化が滞っていたが、2012年にMPI3がリリースされ、MPIのプログラミングパラダイムが少しづつ変わりつつある。同様に大きな進歩をとげているのがC++で、C++99より、C++11が正式に制定され、現在ではC++14が承認され、C++17も規格が策定が進みつつある。MPIを取り巻くC++環境は進化しているのにもかかわらず、MPI3ではC++のBindingを非推奨としてしまった。この理由としてはMPIのC++Bindingの設計がいささか古く、かつMPIフォーラムにおいてC++のメンテナがいないということと、MPIを使ってコードを書くのは主に数値計算を行う研究者で、アプリケーション開発としては過去の資産の関係もありFortranやC言語で十分なことが多いためである。
MPIを取り巻くC++の冷遇としては、近年のC++は黒魔術と言われるほど、ほんとうの意味で習得するのにかなりの労力を必要とすることが考えられる。例えばデザインパターンやテンプレートを使ったメタプログラミングなどは、数値計算を行う研究者にとっては無用の長物とまでは行かないものの、その殆どが必要ないと考えられ、MPIをAPIとして利用する研究者にとってC++を使い難いのかもしれない。

そうは行ってもC++で開発をしたいという開発者は一定数いるため、boost MPIのようにモダンなC++を使ったラッパーが開発されている。残念ながらBoost MPIの更新も2007年以降更新が滞っており、かつ内容もMPI-1.1から2.0で制定された内容で構成され、MPI-2から使えるようになったRemote Memory Accessなどはサポートされていない。

ところで、並列処理が当たり前になってきている昨今において、筆者が思うにMPIは使いにくく感じている。その理由としては、並列処理としてのプログラミングモデルが「スーパーコンピュータ」から発展してきているため分散メモリ型を前提としているため、近年の、特に若年層からすると並列処理はスレッド並列であったり、GPU ComputingなどPCベースから学習しているので、メッセージパッシングというパラダイムがいささか利用しづらいのではないかと考えている。
MPI-3以降NUMAベースの共有メモリ型のRMAがサポートされてきているが、活用している人々はかなり限定されている。
そこで、MPIのRMAの機能とC++11のメタプログラミングを活用して、分散メモリでありながら、共有メモリのように扱える配列を作成したいと考え、このプロジェクトを作成した。
例えば、

std::size_t globalsize = 10000000;
std::size_t init_value = 0.0;

Array<double> vals( globalsize, init_value );

for( auto ii = MPIRank ; ii < 10000000; ii+= MPISize )
{
    vals[ii] = 何らかの計算
}

と言った感じで、配列が扱えればパフォーマンスはさておき、使い勝手は向上すると考えている。

